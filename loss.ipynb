{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff1493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.random as random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "\n",
    "from differentials import expression, domain, boundary, initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c099ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = lambda u: jax.grad(u, argnums=0)\n",
    "dt = lambda u: jax.grad(u, argnums=1)\n",
    "\n",
    "heat = expression(\n",
    "    lambda u: lambda x, t: dt(u)(x, t) + dx(dx(u))(x, t),\n",
    "    var=(\"x\", \"t\"),\n",
    "    boundaries=(\n",
    "        # insulated ends u_x(0, t) = 0\n",
    "        boundary(\n",
    "            LHS=lambda u: lambda x, t: dx(u)(x, t),\n",
    "            RHS=lambda u: lambda x, t: 0.0,\n",
    "            con=(0.0, \"t\")\n",
    "        ),\n",
    "        # insulated end u_x(L, t) = 0\n",
    "        boundary(\n",
    "            LHS=lambda u: lambda x, t: dx(u)(x, t),\n",
    "            RHS=lambda u: lambda x, t: 0.0,\n",
    "            con=(1.0, \"t\")\n",
    "        ),\n",
    "        # inital function. u(x, 0) = sin(x)\n",
    "        initial(\n",
    "            LHS=lambda u: lambda x, t: u(x, t),\n",
    "            RHS=lambda u: lambda x, t: jnp.sin(x),\n",
    "            con=(\"x\", 0.0)\n",
    "        )\n",
    "    ),\n",
    "    x=domain(0, 1),\n",
    "    t=domain(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1dd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ec93da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ScopeParamShapeError",
     "evalue": "Initializer expected to generate shape (4, 5) but got shape (4, 4) instead for parameter \"kernel\" in \"/Dense_2\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScopeParamShapeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     31\u001b[0m heat_loss \u001b[38;5;241m=\u001b[39m make_loss(heat)\n\u001b[0;32m---> 32\u001b[0m heat_loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheat_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(end \u001b[38;5;241m-\u001b[39m start)\n",
      "    \u001b[0;31m[... skipping hidden 19 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m, in \u001b[0;36mmake_loss.<locals>.loss\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     20\u001b[0m     error \u001b[38;5;241m=\u001b[39m expression\u001b[38;5;241m.\u001b[39mloss(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x, t: u_hat\u001b[38;5;241m.\u001b[39mapply(params, jnp\u001b[38;5;241m.\u001b[39marray((x, t)))[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     22\u001b[0m         x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# this is for x and t. No better way exists to do this\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m error\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mmax(\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mmean(jax\u001b[38;5;241m.\u001b[39mvmap(loss_unit)(xs))\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m, in \u001b[0;36mmake_loss.<locals>.loss.<locals>.loss_unit\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_unit\u001b[39m(x):\n\u001b[0;32m---> 20\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[43mexpression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_hat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# this is for x and t. No better way exists to do this\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m error\n",
      "File \u001b[0;32m~/Developer/ai/differentials/differentials.py:47\u001b[0m, in \u001b[0;36mexpression.loss\u001b[0;34m(self, U, *args)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     41\u001b[0m          U: Callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     42\u001b[0m          \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# expression(x1, x2, ... , xn) -> float\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# expression(x1, x2, ... , xn, U=U_validation) -> float\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     boundary_loss \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboundaries_defined:\n",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m u: jax\u001b[38;5;241m.\u001b[39mgrad(u, argnums\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m u: jax\u001b[38;5;241m.\u001b[39mgrad(u, argnums\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m heat \u001b[38;5;241m=\u001b[39m expression(\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m u: \u001b[38;5;28;01mlambda\u001b[39;00m x, t: \u001b[43mdt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m dx(dx(u))(x, t),\n\u001b[1;32m      6\u001b[0m     var\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m     boundaries\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# insulated ends u_x(0, t) = 0\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         boundary(\n\u001b[1;32m     10\u001b[0m             LHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m u: \u001b[38;5;28;01mlambda\u001b[39;00m x, t: dx(u)(x, t),\n\u001b[1;32m     11\u001b[0m             RHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m u: \u001b[38;5;28;01mlambda\u001b[39;00m x, t: \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     12\u001b[0m             con\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m         ),\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# insulated end u_x(L, t) = 0\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         boundary(\n\u001b[1;32m     16\u001b[0m             LHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m u: \u001b[38;5;28;01mlambda\u001b[39;00m x, t: dx(u)(x, t),\n\u001b[1;32m     17\u001b[0m             RHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m u: \u001b[38;5;28;01mlambda\u001b[39;00m x, t: \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     18\u001b[0m             con\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m         ),\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# inital function. u(x, 0) = sin(x)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         initial(\n\u001b[1;32m     22\u001b[0m             LHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m u: \u001b[38;5;28;01mlambda\u001b[39;00m x, t: u(x, t),\n\u001b[1;32m     23\u001b[0m             RHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m u: \u001b[38;5;28;01mlambda\u001b[39;00m x, t: jnp\u001b[38;5;241m.\u001b[39msin(x),\n\u001b[1;32m     24\u001b[0m             con\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     25\u001b[0m         )\n\u001b[1;32m     26\u001b[0m     ),\n\u001b[1;32m     27\u001b[0m     x\u001b[38;5;241m=\u001b[39mdomain(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     28\u001b[0m     t\u001b[38;5;241m=\u001b[39mdomain(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m, in \u001b[0;36mmake_loss.<locals>.loss.<locals>.loss_unit.<locals>.<lambda>\u001b[0;34m(x, t)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_unit\u001b[39m(x):\n\u001b[1;32m     20\u001b[0m     error \u001b[38;5;241m=\u001b[39m expression\u001b[38;5;241m.\u001b[39mloss(\n\u001b[0;32m---> 21\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x, t: \u001b[43mu_hat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     22\u001b[0m         x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# this is for x and t. No better way exists to do this\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m error\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Developer/ai/differentials/model.py:15\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer_width \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_layout:\n\u001b[0;32m---> 15\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mkernel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mbias_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_init\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# x = nn.BatchNorm(use_running_average=not self.train)(x)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mselu(x)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/flax/linen/linear.py:256\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;129m@compact\u001b[39m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Array) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    The transformed input.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m   kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    263\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam(\n\u001b[1;32m    264\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_init, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures,), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_dtype\n\u001b[1;32m    265\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/flax/core/scope.py:982\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, unbox, *init_args, **init_kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m val, abs_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(value_flat, abs_value_flat):\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# NOTE: We could check dtype consistency here as well but it's\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# usefuleness is less obvious. We might intentionally change the dtype\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;66;03m# for inference to a half float type for example.\u001b[39;00m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mshape(val) \u001b[38;5;241m!=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mshape(abs_val):\n\u001b[0;32m--> 982\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeParamShapeError(\n\u001b[1;32m    983\u001b[0m         name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text, jnp\u001b[38;5;241m.\u001b[39mshape(abs_val), jnp\u001b[38;5;241m.\u001b[39mshape(val)\n\u001b[1;32m    984\u001b[0m       )\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mutable_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mScopeParamShapeError\u001b[0m: Initializer expected to generate shape (4, 5) but got shape (4, 4) instead for parameter \"kernel\" in \"/Dense_2\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)"
     ]
    }
   ],
   "source": [
    "u_hat, params = heat.u()\n",
    "\n",
    "x =jnp.array([1.0,2.0])\n",
    "xs = heat.matrix(10)\n",
    "\n",
    "#start val\n",
    "\n",
    "def make_loss(expression, n=40):\n",
    "    u_hat, _ = expression.u((4,4))\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(n)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.max(jax.vmap(loss_unit)(xs))\n",
    "        return jnp.mean(jax.vmap(loss_unit)(xs))\n",
    "        # here there is a contention. What loss is better, the worst point tested, or the average point tested\n",
    "    return jax.jit(loss)\n",
    "\n",
    "start = time.time()\n",
    "heat_loss = make_loss(heat)\n",
    "heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "\n",
    "print(heat_loss)\n",
    "print(grads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76936f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                 | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                                                        | 1/100 [00:08<14:48,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                                                       | 2/100 [00:14<11:22,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|███▏                                                                                                     | 3/100 [00:20<10:13,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|████▏                                                                                                    | 4/100 [00:25<09:39,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    }
   ],
   "source": [
    "# timing the loss / average loss with a mean function vs a min function. \n",
    "\n",
    "def make_mean_loss(expression):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(10)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.mean(jax.vmap(loss_unit)(xs))\n",
    "    return jax.jit(loss)\n",
    "\n",
    "def make_max_loss(expression):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(10)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.max(jax.vmap(loss_unit)(xs))\n",
    "    return jax.jit(loss)\n",
    "\n",
    "# \n",
    "n_10_mean_loss = list()\n",
    "n_10_mean_time = list()\n",
    "n_10_max_loss = list()\n",
    "n_10_max_time = list()\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    print(\"n = 10\")\n",
    "    start = time.time()\n",
    "    heat_loss = make_mean_loss(heat)\n",
    "    heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "    end = time.time()\n",
    "    \n",
    "    n_10_mean_loss.append(heat_loss)\n",
    "    n_10_mean_time.append(end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    heat_loss = make_max_loss(heat)\n",
    "    heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "    end = time.time()\n",
    "    \n",
    "    n_10_max_loss.append(heat_loss)\n",
    "    n_10_max_time.append(end-start)\n",
    "    \n",
    "#.  n = 30\n",
    "\n",
    "def make_mean_loss(expression):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(30)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.mean(jax.vmap(loss_unit)(xs))\n",
    "    return jax.jit(loss)\n",
    "\n",
    "def make_max_loss(expression):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(30)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.max(jax.vmap(loss_unit)(xs))\n",
    "    return jax.jit(loss)\n",
    "\n",
    "# \n",
    "n_30_mean_loss = list()\n",
    "n_30_mean_time = list()\n",
    "n_30_max_loss = list()\n",
    "n_30_max_time = list()\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    print(\"n = 30\")\n",
    "    start = time.time()\n",
    "    heat_loss = make_mean_loss(heat)\n",
    "    heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "    end = time.time()\n",
    "    \n",
    "    n_30_mean_loss.append(heat_loss)\n",
    "    n_30_mean_time.append(end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    heat_loss = make_max_loss(heat)\n",
    "    heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "    end = time.time()\n",
    "    \n",
    "    n_30_max_loss.append(heat_loss)\n",
    "    n_30_max_time.append(end-start)\n",
    "\n",
    "# displaying\n",
    "\n",
    "n_30_mean_loss_arr = jnp.array(n_30_mean_loss)\n",
    "n_30_mean_time_arr = jnp.array(n_30_mean_time)\n",
    "n_30_max_loss_arr = jnp.array(n_30_max_loss)\n",
    "n_30_max_time_arr = jnp.array(n_30_max_time)\n",
    "\n",
    "n_10_mean_loss_arr = jnp.array(n_10_mean_loss)\n",
    "n_10_mean_time_arr = jnp.array(n_10_mean_time)\n",
    "n_10_max_loss_arr = jnp.array(n_10_max_loss)\n",
    "n_10_max_time_arr = jnp.array(n_10_max_time)\n",
    "\n",
    "# Compute mean and standard deviation for n = 30\n",
    "n_30_mean_loss_mean = jnp.mean(n_30_mean_loss_arr)\n",
    "n_30_mean_loss_std = jnp.std(n_30_mean_loss_arr)\n",
    "n_30_mean_time_mean = jnp.mean(n_30_mean_time_arr)\n",
    "n_30_mean_time_std = jnp.std(n_30_mean_time_arr)\n",
    "\n",
    "n_30_max_loss_mean = jnp.mean(n_30_max_loss_arr)\n",
    "n_30_max_loss_std = jnp.std(n_30_max_loss_arr)\n",
    "n_30_max_time_mean = jnp.mean(n_30_max_time_arr)\n",
    "n_30_max_time_std = jnp.std(n_30_max_time_arr)\n",
    "\n",
    "# Compute mean and standard deviation for n = 10\n",
    "n_10_mean_loss_mean = jnp.mean(n_10_mean_loss_arr)\n",
    "n_10_mean_loss_std = jnp.std(n_10_mean_loss_arr)\n",
    "n_10_mean_time_mean = jnp.mean(n_10_mean_time_arr)\n",
    "n_10_mean_time_std = jnp.std(n_10_mean_time_arr)\n",
    "\n",
    "n_10_max_loss_mean = jnp.mean(n_10_max_loss_arr)\n",
    "n_10_max_loss_std = jnp.std(n_10_max_loss_arr)\n",
    "n_10_max_time_mean = jnp.mean(n_10_max_time_arr)\n",
    "n_10_max_time_std = jnp.std(n_10_max_time_arr)\n",
    "\n",
    "# Print results in a summary table format, including the actual statistics\n",
    "print(f\"{'Sample Size':<12} {'Method':<6} {'Metric':<5} {'Mean':<10} {'Standard Deviation':<10}\")\n",
    "print(f\"{'n = 30':<12} {'Mean':<6} {'Loss':<5} {n_30_mean_loss_mean:<10.4f} {n_30_mean_loss_std:<10.4f}\")\n",
    "print(f\"{'n = 30':<12} {'Mean':<6} {'Time':<5} {n_30_mean_time_mean:<10.4f} {n_30_mean_time_std:<10.4f}\")\n",
    "print(f\"{'n = 10':<12} {'Mean':<6} {'Loss':<5} {n_10_mean_loss_mean:<10.4f} {n_10_mean_loss_std:<10.4f}\")\n",
    "print(f\"{'n = 10':<12} {'Mean':<6} {'Time':<5} {n_10_mean_time_mean:<10.4f} {n_10_mean_time_std:<10.4f}\")\n",
    "print()\n",
    "print(f\"{'n = 30':<12} {'Max':<6} {'Loss':<5} {n_30_max_loss_mean:<10.4f} {n_30_max_loss_std:<10.4f}\")\n",
    "print(f\"{'n = 30':<12} {'Max':<6} {'Time':<5} {n_30_max_time_mean:<10.4f} {n_30_max_time_std:<10.4f}\")\n",
    "print(f\"{'n = 10':<12} {'Max':<6} {'Loss':<5} {n_10_max_loss_mean:<10.4f} {n_10_max_loss_std:<10.4f}\")\n",
    "print(f\"{'n = 10':<12} {'Max':<6} {'Time':<5} {n_10_max_time_mean:<10.4f} {n_10_max_time_std:<10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bd79d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1854978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

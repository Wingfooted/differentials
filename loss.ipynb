{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff1493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.random as random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "\n",
    "from differentials import expression, domain, boundary, initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c099ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = lambda u: jax.grad(u, argnums=0)\n",
    "dt = lambda u: jax.grad(u, argnums=1)\n",
    "\n",
    "heat = expression(\n",
    "    lambda u: lambda x, t: dt(u)(x, t) + dx(dx(u))(x, t),\n",
    "    var=(\"x\", \"t\"),\n",
    "    boundaries=(\n",
    "        # insulated ends u_x(0, t) = 0\n",
    "        boundary(\n",
    "            LHS=lambda u: lambda x, t: dx(u)(x, t),\n",
    "            RHS=lambda u: lambda x, t: 0.0,\n",
    "            con=(0.0, \"t\")\n",
    "        ),\n",
    "        # insulated end u_x(L, t) = 0\n",
    "        boundary(\n",
    "            LHS=lambda u: lambda x, t: dx(u)(x, t),\n",
    "            RHS=lambda u: lambda x, t: 0.0,\n",
    "            con=(1.0, \"t\")\n",
    "        ),\n",
    "        # inital function. u(x, 0) = sin(x)\n",
    "        initial(\n",
    "            LHS=lambda u: lambda x, t: u(x, t),\n",
    "            RHS=lambda u: lambda x, t: jnp.sin(x),\n",
    "            con=(\"x\", 0.0)\n",
    "        )\n",
    "    ),\n",
    "    x=domain(0, 1),\n",
    "    t=domain(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f1c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pde_loss(expression):\n",
    "    u_hat, _ = expression.u((4, 4, 4))\n",
    "    def loss(params):\n",
    "        # make values\n",
    "        n = 30  # hyper parameter, mean samples taken\n",
    "        xs_matrix = expression.matrix(n)\n",
    "        def rnd_instance_val(x):\n",
    "            print(x)\n",
    "            print(*[num for num in x])\n",
    "            error = expression.loss(\n",
    "                    lambda x, t: u_hat.apply(params, jnp.array((x, t))),\n",
    "                    *[num for num in x]\n",
    "            )\n",
    "            print(\"here\", error)\n",
    "            return error\n",
    "\n",
    "        return jnp.mean(jax.vmap(rnd_instance_val, in_axes=0)(xs_matrix))\n",
    "    return jax.jit(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df1dd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3ec93da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.055876016616821\n",
      "1.6818761\n",
      "{'params': {'Dense_0': {'bias': Array([-6.8500056,  5.8860106], dtype=float32), 'kernel': Array([[-3.5157905 ,  2.8558013 ],\n",
      "       [ 1.4642328 , -0.82544225]], dtype=float32)}, 'Dense_1': {'bias': Array([-2.7510614, -2.0679293, -4.046641 , -2.609736 ], dtype=float32), 'kernel': Array([[-0.38641772, -0.12640245, -0.28966168, -0.28075045],\n",
      "       [-1.4686193 , -1.3215141 , -1.7179074 , -1.548946  ]],      dtype=float32)}, 'Dense_2': {'bias': Array([ 3.577105  , -2.9246707 , -0.22836965, -0.91325915, -0.2636633 ],      dtype=float32), 'kernel': Array([[-0.5927569 ,  0.65043473,  0.12628253,  0.17360386,  0.14536926],\n",
      "       [ 0.01639794,  0.08647421,  0.04295447, -0.03324792, -0.10653525],\n",
      "       [-0.78152436,  0.9497759 ,  0.21021459,  0.20418186,  0.09124723],\n",
      "       [-0.74358386,  0.8820211 ,  0.18833487,  0.2019265 ,  0.11008704]],      dtype=float32)}, 'Dense_3': {'bias': Array([-2.0352938,  0.6796228, -1.2621865,  1.8939246, -1.1580145],      dtype=float32), 'kernel': Array([[-1.4912994 ,  0.5018593 , -1.1281773 ,  1.6992434 , -1.0877326 ],\n",
      "       [ 0.1302013 , -0.04079686,  0.1083331 , -0.1432551 ,  0.17160009],\n",
      "       [-0.24961014,  0.08217957, -0.19603597,  0.28100076, -0.22763349],\n",
      "       [ 0.4697181 , -0.16519113,  0.3389764 , -0.54848164,  0.17284371],\n",
      "       [-0.36522916,  0.12331725, -0.27591774,  0.41645464, -0.25516033]],      dtype=float32)}, 'Dense_4': {'bias': Array([-0.7070541 , -0.38316426,  2.2565856 , -0.4006692 ], dtype=float32), 'kernel': Array([[ 0.7781055 ,  0.6190737 , -1.9820797 ,  0.5991527 ],\n",
      "       [-0.49683496, -0.45911366,  1.6091694 , -0.5271391 ],\n",
      "       [ 0.13446322,  0.12415277, -0.43555   ,  0.14213043],\n",
      "       [ 0.02365966,  0.00924467, -0.01099144, -0.00831651],\n",
      "       [-0.42246026, -0.33252668,  1.0601014 , -0.30666572]],      dtype=float32)}, 'Dense_5': {'bias': Array([-1.6924273], dtype=float32), 'kernel': Array([[ 1.2009493 ],\n",
      "       [ 0.13580991],\n",
      "       [-3.2107356 ],\n",
      "       [-1.3899583 ]], dtype=float32)}}}\n"
     ]
    }
   ],
   "source": [
    "u_hat, params = heat.u()\n",
    "\n",
    "x =jnp.array([1.0,2.0])\n",
    "xs = heat.matrix(10)\n",
    "\n",
    "#start val\n",
    "def val(x):\n",
    "    error = heat.loss(\n",
    "            lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "            x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "    )\n",
    "    return error\n",
    "\n",
    "def make_loss(expression, n=40):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(n)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.max(jax.vmap(loss_unit)(xs))\n",
    "        return jnp.mean(jax.vmap(loss_unit)(xs))\n",
    "        # here there is a contention. What loss is better, the worst point tested, or the average point tested\n",
    "    return jax.jit(loss)\n",
    "\n",
    "start = time.time()\n",
    "heat_loss = make_loss(heat)\n",
    "heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "\n",
    "print(heat_loss)\n",
    "print(grads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76936f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                 | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                                                        | 1/100 [00:08<14:48,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                                                       | 2/100 [00:14<11:22,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|███▏                                                                                                     | 3/100 [00:20<10:13,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|████▏                                                                                                    | 4/100 [00:25<09:39,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10\n"
     ]
    }
   ],
   "source": [
    "# timing the loss / average loss with a mean function vs a min function. \n",
    "\n",
    "def make_mean_loss(expression):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(10)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.mean(jax.vmap(loss_unit)(xs))\n",
    "    return jax.jit(loss)\n",
    "\n",
    "def make_max_loss(expression):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(10)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.max(jax.vmap(loss_unit)(xs))\n",
    "    return jax.jit(loss)\n",
    "\n",
    "# \n",
    "n_10_mean_loss = list()\n",
    "n_10_mean_time = list()\n",
    "n_10_max_loss = list()\n",
    "n_10_max_time = list()\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    print(\"n = 10\")\n",
    "    start = time.time()\n",
    "    heat_loss = make_mean_loss(heat)\n",
    "    heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "    end = time.time()\n",
    "    \n",
    "    n_10_mean_loss.append(heat_loss)\n",
    "    n_10_mean_time.append(end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    heat_loss = make_max_loss(heat)\n",
    "    heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "    end = time.time()\n",
    "    \n",
    "    n_10_max_loss.append(heat_loss)\n",
    "    n_10_max_time.append(end-start)\n",
    "    \n",
    "#.  n = 30\n",
    "\n",
    "def make_mean_loss(expression):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(30)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.mean(jax.vmap(loss_unit)(xs))\n",
    "    return jax.jit(loss)\n",
    "\n",
    "def make_max_loss(expression):\n",
    "    u_hat, _ = expression.u()\n",
    "    # hyper param, num of samples per loss\n",
    "    xs = expression.matrix(30)\n",
    "    def loss(params):\n",
    "        def loss_unit(x):\n",
    "            error = expression.loss(\n",
    "                lambda x, t: u_hat.apply(params, jnp.array((x, t)))[0],\n",
    "                x[0], x[1]  # this is for x and t. No better way exists to do this\n",
    "            )\n",
    "            return error\n",
    "        return jnp.max(jax.vmap(loss_unit)(xs))\n",
    "    return jax.jit(loss)\n",
    "\n",
    "# \n",
    "n_30_mean_loss = list()\n",
    "n_30_mean_time = list()\n",
    "n_30_max_loss = list()\n",
    "n_30_max_time = list()\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    print(\"n = 30\")\n",
    "    start = time.time()\n",
    "    heat_loss = make_mean_loss(heat)\n",
    "    heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "    end = time.time()\n",
    "    \n",
    "    n_30_mean_loss.append(heat_loss)\n",
    "    n_30_mean_time.append(end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    heat_loss = make_max_loss(heat)\n",
    "    heat_loss, grads = jax.value_and_grad(heat_loss)(params)\n",
    "    end = time.time()\n",
    "    \n",
    "    n_30_max_loss.append(heat_loss)\n",
    "    n_30_max_time.append(end-start)\n",
    "\n",
    "# displaying\n",
    "\n",
    "n_30_mean_loss_arr = jnp.array(n_30_mean_loss)\n",
    "n_30_mean_time_arr = jnp.array(n_30_mean_time)\n",
    "n_30_max_loss_arr = jnp.array(n_30_max_loss)\n",
    "n_30_max_time_arr = jnp.array(n_30_max_time)\n",
    "\n",
    "n_10_mean_loss_arr = jnp.array(n_10_mean_loss)\n",
    "n_10_mean_time_arr = jnp.array(n_10_mean_time)\n",
    "n_10_max_loss_arr = jnp.array(n_10_max_loss)\n",
    "n_10_max_time_arr = jnp.array(n_10_max_time)\n",
    "\n",
    "# Compute mean and standard deviation for n = 30\n",
    "n_30_mean_loss_mean = jnp.mean(n_30_mean_loss_arr)\n",
    "n_30_mean_loss_std = jnp.std(n_30_mean_loss_arr)\n",
    "n_30_mean_time_mean = jnp.mean(n_30_mean_time_arr)\n",
    "n_30_mean_time_std = jnp.std(n_30_mean_time_arr)\n",
    "\n",
    "n_30_max_loss_mean = jnp.mean(n_30_max_loss_arr)\n",
    "n_30_max_loss_std = jnp.std(n_30_max_loss_arr)\n",
    "n_30_max_time_mean = jnp.mean(n_30_max_time_arr)\n",
    "n_30_max_time_std = jnp.std(n_30_max_time_arr)\n",
    "\n",
    "# Compute mean and standard deviation for n = 10\n",
    "n_10_mean_loss_mean = jnp.mean(n_10_mean_loss_arr)\n",
    "n_10_mean_loss_std = jnp.std(n_10_mean_loss_arr)\n",
    "n_10_mean_time_mean = jnp.mean(n_10_mean_time_arr)\n",
    "n_10_mean_time_std = jnp.std(n_10_mean_time_arr)\n",
    "\n",
    "n_10_max_loss_mean = jnp.mean(n_10_max_loss_arr)\n",
    "n_10_max_loss_std = jnp.std(n_10_max_loss_arr)\n",
    "n_10_max_time_mean = jnp.mean(n_10_max_time_arr)\n",
    "n_10_max_time_std = jnp.std(n_10_max_time_arr)\n",
    "\n",
    "# Print results in a summary table format, including the actual statistics\n",
    "print(f\"{'Sample Size':<12} {'Method':<6} {'Metric':<5} {'Mean':<10} {'Standard Deviation':<10}\")\n",
    "print(f\"{'n = 30':<12} {'Mean':<6} {'Loss':<5} {n_30_mean_loss_mean:<10.4f} {n_30_mean_loss_std:<10.4f}\")\n",
    "print(f\"{'n = 30':<12} {'Mean':<6} {'Time':<5} {n_30_mean_time_mean:<10.4f} {n_30_mean_time_std:<10.4f}\")\n",
    "print(f\"{'n = 10':<12} {'Mean':<6} {'Loss':<5} {n_10_mean_loss_mean:<10.4f} {n_10_mean_loss_std:<10.4f}\")\n",
    "print(f\"{'n = 10':<12} {'Mean':<6} {'Time':<5} {n_10_mean_time_mean:<10.4f} {n_10_mean_time_std:<10.4f}\")\n",
    "print()\n",
    "print(f\"{'n = 30':<12} {'Max':<6} {'Loss':<5} {n_30_max_loss_mean:<10.4f} {n_30_max_loss_std:<10.4f}\")\n",
    "print(f\"{'n = 30':<12} {'Max':<6} {'Time':<5} {n_30_max_time_mean:<10.4f} {n_30_max_time_std:<10.4f}\")\n",
    "print(f\"{'n = 10':<12} {'Max':<6} {'Loss':<5} {n_10_max_loss_mean:<10.4f} {n_10_max_loss_std:<10.4f}\")\n",
    "print(f\"{'n = 10':<12} {'Max':<6} {'Time':<5} {n_10_max_time_mean:<10.4f} {n_10_max_time_std:<10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bd79d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1854978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
